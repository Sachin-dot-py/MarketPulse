{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "from spacy.language import Language\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_excel('stocksGood.xlsx')\n",
    "firms = list(df['Column3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1485"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(firms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_name(firm_name):\n",
    "  return firm_name.replace(\"Inc.\", \"\").replace('Holdings', '').replace('Corp.', '').replace('Solutions','').replace('Services','').replace(\"Corporation\", \"\").replace(\",\", \"\").replace(\"PLC\", \"\").replace(\"Ltd.\", \"\").replace('Platforms', '').replace('News','').replace('Institution','').replace('research','').replace('Replace','').replace('news','').replace('advantage','').strip().lower()\n",
    "\n",
    "name_to_ticker = df.assign(Column4 = df['Column3'].apply(better_name)).set_index('Column4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column4</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nvidia</th>\n",
       "      <td>1</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>2</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft</th>\n",
       "      <td>3</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon</th>\n",
       "      <td>4</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon.com</th>\n",
       "      <td>4</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trubridge</th>\n",
       "      <td>1496</td>\n",
       "      <td>TBRG</td>\n",
       "      <td>TruBridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spok</th>\n",
       "      <td>1497</td>\n",
       "      <td>SPOK</td>\n",
       "      <td>Spok Holdings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viemed healthcare</th>\n",
       "      <td>1498</td>\n",
       "      <td>VMD</td>\n",
       "      <td>Viemed Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>park-ohio</th>\n",
       "      <td>1499</td>\n",
       "      <td>PKOH</td>\n",
       "      <td>Park-Ohio Holdings Corp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>denny's</th>\n",
       "      <td>1500</td>\n",
       "      <td>DENN</td>\n",
       "      <td>Denny's Corporation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1485 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Column1 Column2                   Column3\n",
       "Column4                                                     \n",
       "nvidia                   1    NVDA        NVIDIA Corporation\n",
       "apple                    2    AAPL                Apple Inc.\n",
       "microsoft                3    MSFT     Microsoft Corporation\n",
       "amazon                   4    AMZN                    Amazon\n",
       "amazon.com               4    AMZN                Amazon.com\n",
       "...                    ...     ...                       ...\n",
       "trubridge             1496    TBRG                 TruBridge\n",
       "spok                  1497    SPOK             Spok Holdings\n",
       "viemed healthcare     1498     VMD         Viemed Healthcare\n",
       "park-ohio             1499    PKOH  Park-Ohio Holdings Corp.\n",
       "denny's               1500    DENN       Denny's Corporation\n",
       "\n",
       "[1485 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_to_t(lst):\n",
    "  return_lst = []\n",
    "  lst = [x.lower() for x in lst]\n",
    "  def helper(x):\n",
    "    try:\n",
    "      a = name_to_ticker.loc[x]['Column2']\n",
    "      if (isinstance(a, str)):\n",
    "        if ((a!='RSSS') & (a!='BPOP') & (a!='PINC') & (a!='AWRE') & (a!='NICE') & (a!='ADV') & (a!='BKNG') & (a!='DALN') & (a!='STHO')):\n",
    "          return a\n",
    "        else:\n",
    "          return False\n",
    "      else:\n",
    "        return name_to_ticker.loc[x]['Column2'][-1]\n",
    "    except:\n",
    "      return False\n",
    "\n",
    "  return_lst = list(map(lambda x: helper(x), lst))\n",
    "  return return_lst\n",
    "  #except:\n",
    "   # return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rubbish(df):\n",
    "    def remove_false(lst):\n",
    "        try:\n",
    "            if (False in lst):\n",
    "                while False in lst:\n",
    "                    lst.remove(False)\n",
    "                return lst\n",
    "            else:\n",
    "                return lst\n",
    "        except:\n",
    "            return lst\n",
    "    try:\n",
    "        df['ticker'] = df['ticker'].apply(remove_false)\n",
    "        df = df.dropna(axis='index', how='any')\n",
    "        return df\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_names = firms\n",
    "def preprocess_company_names(company_names):\n",
    "    processed_names = []\n",
    "    for name in company_names:\n",
    "        core_name = name.replace(\"Inc.\", \"\").replace('Holdings', '').replace('Corp.', '').replace('Solutions','').replace('Services','').replace(\"Corporation\", \"\").replace(\",\", \"\").replace(\"PLC\", \"\").replace(\"Ltd.\", \"\").replace('Platforms', '').replace('News','').replace('Institution','').replace('research','').replace('Replace','').replace('news','').strip()\n",
    "        processed_names.append(core_name)\n",
    "    try:\n",
    "        return list(set(processed_names)) \n",
    "    except:\n",
    "        return None\n",
    "core_company_names = preprocess_company_names(company_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.company_ner_component(doc)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "\n",
    "patterns = list(nlp.pipe(core_company_names))\n",
    "matcher.add(\"COMPANY\", patterns)\n",
    "\n",
    "@Language.component(\"company_ner_component\")\n",
    "def company_ner_component(doc):\n",
    "    matches = matcher(doc)\n",
    "    spans = []\n",
    "    for match_id, start, end in matches:\n",
    "        span = Span(doc, start, end, label=\"COMPANY\")\n",
    "        spans.append(span)\n",
    "\n",
    "    doc.ents = spacy.util.filter_spans(spans)\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"company_ner_component\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_companies(text):\n",
    "  doc = nlp(text)\n",
    "  detected_firms = set()\n",
    "  for ent in doc.ents:\n",
    "    if (ent.label_ == \"COMPANY\"):\n",
    "      detected_firms.add(ent.text)\n",
    "  if (len(detected_firms) == 0):\n",
    "    return None\n",
    "  return list(detected_firms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_companies('Apple was sued')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the scraped data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenji\\AppData\\Local\\Temp\\ipykernel_42372\\3181200238.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return name_to_ticker.loc[x]['Column2'][-1]\n"
     ]
    }
   ],
   "source": [
    "financial_news = pd.read_csv(\"new-complete-scraped-articles.csv\")\n",
    "#b = financial_news[financial_news['title'].str.contains('Amazon')]\n",
    "\n",
    "financial_news = financial_news.assign(firms = financial_news['title'].apply(find_companies))\n",
    "financial_news = financial_news.dropna(axis='index', how='any')\n",
    "financial_news = financial_news.assign(ticker = financial_news['firms'].apply(n_to_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = financial_news.explode('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna(axis='index', how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['combined'] = train_data.apply(lambda row: [row['ticker'], row['publish_date']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[-1]['publish_date']\n",
    "def clean_time(tim):\n",
    "    if (tim[-6:]=='-05:00'):\n",
    "        return tim[:-6]\n",
    "    return tim\n",
    "\n",
    "train_data['publish_date'] = train_data['publish_date'].apply(clean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def round_down_datetime(dt, period_minutes=60):\n",
    "    if not isinstance(dt, datetime):\n",
    "        try:\n",
    "            dt = datetime.strptime(dt, \"%Y-%m-%d %H:%M:%S\")\n",
    "        except:\n",
    "            dt = datetime.now()\n",
    "\n",
    "    period_seconds = period_minutes * 60\n",
    "    seconds_since_midnight = (dt - datetime.combine(dt.date(), datetime.min.time())).total_seconds()\n",
    "    rounded_seconds = (seconds_since_midnight // period_seconds) * period_seconds\n",
    "    return dt.replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(seconds=rounded_seconds)\n",
    "\n",
    "\n",
    "def calculate_cumulative_sum(df, up_to_time):\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"The DataFrame index must be a DatetimeIndex.\")\n",
    "    filtered_df = df.between_time(\"00:00\", up_to_time)\n",
    "    cumulative_daily_sum = filtered_df.groupby(filtered_df.index.date).cumsum()\n",
    "    return cumulative_daily_sum\n",
    "\n",
    "\n",
    "from functools import cache\n",
    "\n",
    "@cache\n",
    "def download_data_from_datetime(ticker, start_datetime=None, end_datetime=None, interval=\"60m\"):\n",
    "    if start_datetime is None and end_datetime is None:\n",
    "        end_dt = round_down_datetime(datetime.now(),period_minutes=60)\n",
    "        start_dt = end_dt - timedelta(days=31)\n",
    "    elif start_datetime is not None and end_datetime is not None:\n",
    "\n",
    "        end_dt = end_datetime\n",
    "        start_dt = start_datetime\n",
    "        pass\n",
    "    else:\n",
    "        \n",
    "        raise ValueError\n",
    " \n",
    "    df = yf.download(ticker, start=start_dt, end=end_dt, interval=interval)\n",
    "    return df\n",
    "\n",
    "def ticker_vol_price_df(ticker, days_before=31, end_datetime=None):\n",
    "\n",
    "    if end_datetime is None:\n",
    "        end_datetime = datetime.now()\n",
    "\n",
    "    try:\n",
    "   \n",
    "        rounded_down_dt = round_down_datetime(end_datetime)\n",
    "        print(rounded_down_dt)\n",
    "\n",
    "        start_datetime_obj = rounded_down_dt - timedelta(days=days_before)\n",
    "        start_datetime = start_datetime_obj\n",
    "        end_datetime = rounded_down_dt\n",
    "\n",
    "        df = download_data_from_datetime(ticker, start_datetime=start_datetime, end_datetime=end_datetime, interval=\"60m\")\n",
    "        \n",
    "        cumulative_sum_df = calculate_cumulative_sum(df, up_to_time=end_datetime.time())\n",
    "       \n",
    "        ticker_price_df = cumulative_sum_df.groupby(cumulative_sum_df.index.date).tail(1)\n",
    "        return ticker_price_df\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def give_vol(lst):\n",
    "    if (isinstance(lst[0], str) == False):\n",
    "        return None\n",
    "    ticker = lst[0]\n",
    "    end_datetime = lst[1]\n",
    "    try:\n",
    "        df = ticker_vol_price_df(ticker, days_before=31,end_datetime=end_datetime)['Volume']\n",
    "        return (df.tail(1)/(df[-30:-1].mean())).values[0][0]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def price_change(lst):\n",
    "    if (isinstance(lst[0], str) == False):\n",
    "        return None\n",
    "    ticker = lst[0]\n",
    "    end_datetime = lst[1]\n",
    "    end_dt = round_down_datetime(end_datetime).date()\n",
    "    start_dt = end_dt - timedelta(days=2)\n",
    "    df = download_data_from_datetime(ticker, start_dt, end_dt, interval=\"1d\")\n",
    "    try:\n",
    "        return df['Close'].pct_change().values[1][0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-23 16:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8684515514244963"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_vol(['META','2025-01-23 16:30:00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_data.assign(vol_prop = train_data['combined'].apply(give_vol))\n",
    "train_data2 = train_data.assign(price_percent = train_data['combined'].apply(price_change))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe1 = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "\n",
    "def finbert(text):\n",
    "        \n",
    "    text = text[:1500]\n",
    "    d = pipe1(text)[0]\n",
    "    if (d['label']=='neutral'):\n",
    "        return 0\n",
    "    elif (d['label']=='positive'):\n",
    "        return d['score']\n",
    "    else:\n",
    "        return -d['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2.to_csv(\"training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data3 = train_data2.dropna().assign(finbert_score = train_data2.dropna()['text'].apply(finbert)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data3.to_csv('train_data_with_finbert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "df = df.dropna()  \n",
    "\n",
    "\n",
    "X = df[['title', 'text', 'vol_prop','finbert_score']]\n",
    "y = df['price_percent']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=2)\n",
    "\n",
    "text_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('headline_tfidf', TfidfVectorizer(), 'title')#,\n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    text_preprocessor,\n",
    "    StandardScaler(with_mean=False),  \n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "\n",
    "joblib.dump(pipeline, 'regression_model_2.pkl')\n",
    "print(\"Model saved to 'regression_model_2.pkl'\")\n",
    "\n",
    "#For predicting\n",
    "#prediction = pipeline.predict(example)\n",
    "#print(\"Predicted Price Change:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
